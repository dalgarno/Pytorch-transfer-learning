{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "\n",
    "from torchvision import datasets, models, transforms, utils\n",
    "\n",
    "from data_utils import DogBreeds\n",
    "from model_helpers import train_model, test_model, get_model_predictions\n",
    "from PIL import Image, ImageFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BASE_PATH = os.getcwd()\n",
    "use_gpu = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rotate_image(image):\n",
    "    if np.random.uniform() < 0.5:\n",
    "        return image.rotate(np.random.uniform(-15, 15))\n",
    "    return image\n",
    "\n",
    "def blur_image(image):\n",
    "    if np.random.uniform() < 0.5:\n",
    "        return image.filter(ImageFilter.GaussianBlur(radius=2))\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomSizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.Lambda(lambda x: rotate_image(x)),\n",
    "        transforms.Lambda(lambda x: blur_image(x)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Scale(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dogs_train = DogBreeds('labels.csv', BASE_PATH, transform=data_transforms['train'], data_split='train')\n",
    "dogs_valid = DogBreeds('labels.csv', BASE_PATH, transform=data_transforms['val'], data_split='valid')\n",
    "dogs_test = DogBreeds('labels.csv', BASE_PATH, transform=data_transforms['val'], data_split='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(dogs_train, batch_size=16,shuffle=True, num_workers=4)\n",
    "valid_dataloader = DataLoader(dogs_valid, batch_size=16,shuffle=False, num_workers=4)\n",
    "test_dataloader = DataLoader(dogs_test, batch_size=16,shuffle=False, num_workers=4)\n",
    "\n",
    "datasets = {\n",
    "    'train': train_dataloader,\n",
    "    'valid': valid_dataloader,\n",
    "    'test': test_dataloader\n",
    "}\n",
    "\n",
    "dataset_sizes = {\n",
    "    'train': len(dogs_train),\n",
    "    'valid': len(dogs_valid),\n",
    "    'test': len(dogs_test)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_ft = models.resnet18(pretrained=True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, 120)\n",
    "\n",
    "if use_gpu:\n",
    "    model_ft = model_ft.cuda()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading fine tuned model...\n",
      "loaded\n"
     ]
    }
   ],
   "source": [
    "MODEL_SAVE_PATH = os.path.join(os.getcwd(), 'finetuned_resnet18')\n",
    "if os.path.exists(MODEL_SAVE_PATH):\n",
    "    print(\"Loading fine tuned model...\")\n",
    "    model_ft = torch.load(MODEL_SAVE_PATH)\n",
    "    print(\"loaded\")\n",
    "else:\n",
    "    print(\"Training model\")\n",
    "    model_ft = train_model(model_ft, criterion, optimizer_ft, \n",
    "                           exp_lr_scheduler, datasets, dataset_sizes,\n",
    "                           use_gpu, num_epochs=25)\n",
    "    torch.save(model_ft, MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: 0.0421 Acc: 0.8113\n"
     ]
    }
   ],
   "source": [
    "ft_resnet18 = torch.load(MODEL_SAVE_PATH)\n",
    "test_model(ft_resnet18, criterion, optimizer_ft, \n",
    "           exp_lr_scheduler, datasets, dataset_sizes,\n",
    "           use_gpu, num_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SUBMISSION_FILES = os.path.join(os.getcwd(), 'test')\n",
    "SUBMISSION_IMAGE_LABELS = os.path.join(os.getcwd(), 'submission_images.csv')\n",
    "SUBMISSION_CSV_PATH = os.path.join(BASE_PATH, 'submission.csv')\n",
    "list_submission_image_names = [x[:-4] for x in os.listdir(SUBMISSION_FILES)] # remove .jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission_transform = transforms.Compose([\n",
    "        transforms.Scale(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "\n",
    "submission_data = DogBreeds('submission_images.csv', BASE_PATH, transform=submission_transform, data_split='submission')\n",
    "submission_dataloader = DataLoader(submission_data, batch_size=1,shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_model_predictions(ft_resnet18, optimizer_ft, \n",
    "                      dogs_train.unique_labels, SUBMISSION_CSV_PATH, \n",
    "                      submission_dataloader, list_submission_image_names,\n",
    "                      use_gpu, num_epochs=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
